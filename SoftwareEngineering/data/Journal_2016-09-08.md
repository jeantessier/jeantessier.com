A colleague started a discussion of the
[test pyramid](https://martinfowler.com/bliki/TestPyramid.html), with lots of
unit tests at the bottom, fewer integration tests in the middle, and a few
end-to-end tests at the top.  I'm afraid of the inertia that all these unit
tests can create.  On more than one project, I've happily created many, many
unit tests (yeah TDD).  Then, I find out much later that making one refactoring
will need to touch a disproportionately large number of tests, or that adding a
variation of some piece of code should include a whole slew of tests, like the
other variations.  So I find myself warming up to having large end-to-end tests
provide a lot of coverage and keep the low-level unit tests to a minimum and
very closely related to the specificity of the code they are testing.  Less of a
pyramid, more like a tower?  Someone mentioned the
[testing cupcake anti-pattern](https://www.thoughtworks.com/insights/blog/introducing-software-testing-cupcake-anti-pattern).

I remember reading an article where the author advocated writing lots of unit
tests to guide TDD but only keeping the acceptance tests in the end.  I don't
think he even bothered to check them into source control.  I can't seem to find
the article anymore.

As I was searching the web for downsides to unit tests, I came across an article
that was
[critical of agile methodologies](http://mikehadlow.blogspot.cl/2014/06/heisenberg-developers.html).
It's main argument is that demanding predictable results kills creativity and
serendipity in developing software.  Building software is so complex and so
dependent on creativity that making estimates is intrinsically unreliable.  It
reminds me of another article I had read about the tyranny of the burndown chart
and some people's perception of Scrum as micromanagement.  This article also
taps into my hatred for
[Jira](https://www.atlassian.com/software/jira) (and all things Atlassian).
