In LangChain4j, I'm using Guice to inject the model, based on command-line
arguments.

In JavaScript, I'm playing with LangChain's output parsers.

I'm trying out LangChain in Ruby, for comparison with Java and JavaScript.

I connected my LangChain examples to Google's Gemini LLM.  My ChatGPT and Claude
API keys don't have any credits, so I can only assess that my code is connecting
with the LLMs by looking for the error message.  But Gemini lets me do queries
for free, so I get to see actual results.
