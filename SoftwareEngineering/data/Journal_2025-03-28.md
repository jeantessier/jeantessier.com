I read
[The Software Engineering Identity Crisis](https://annievella.com/posts/the-software-engineering-identity-crisis/),
by Annie Vella, about how GenAI is changing how people are writing code.  I, for
one, find joy in building code.  It is not satisfying to watch a machine
generate clunky substitutes.  The article talks of a broadening of my profession
and new specializations will emerge.  It is a new cycle of the industrial
revolution.

I like to think about it as similar to when we started using programming
languages.  The previous generation was proud of their skill with assembly,
crafting precise series of instructions optimized for their hardware.  Compilers
could do the same, and often better, in a fraction of the time.  It freed the
programmers to focus on ever higher concerns.  Now, GenAI can generate our code
in a fraction of the time.  It is not as well crafted, not as optimal, not as
elegant, but does it free us to focus on even higher concerns?

Something similar happened when we started to rely more and more on packages
written by strangers on the Internet.  Instead of crafting our code from
scratch, we now import megabytes of modules to do the heavy lifting for us.
These modules have various levels of quality and provide a certain level of
bloat.  But, they save us a lot of time and mental energy.  Why re-invent the
wheel when there is a very usable one over there?

Is GenAI just the latest iteration of this evolution?

The article mentions that when humans work together, a bond of trust forms.
When humans work with GenAI, the trust starts high but erodes rather quickly.
When I work with someone, I expect them to learn from our mistakes and not
repeat errors we've already corrected.  I cannot say the same about GenAI.  It
will blindly generate code that does not work and not learn from it.  I can
expect the similar broken code in the future, either the same one or some new
hallucination.
